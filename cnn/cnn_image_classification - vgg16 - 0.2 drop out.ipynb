{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cnn_image_classification - vgg16 - 0.2 drop out.ipynb","provenance":[{"file_id":"1WgZ204QELrZiEvYjnho7UeItFw-mlxBb","timestamp":1589188756722},{"file_id":"14-JNtqaXLE66a2Vtt-8k4S07lxZOLVqH","timestamp":1589048768803}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"vB5rW3zjr58I","outputId":"c94aa0a9-ab1f-4631-d7e4-560166ea247f","executionInfo":{"status":"ok","timestamp":1589214934565,"user_tz":-420,"elapsed":4865,"user":{"displayName":"Duc Trinh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3DueJ-17c3iJPH_c7OMUo_rfEVfRvjkQWSrqG=s64","userId":"03125855697250476054"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["#Sources used: https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751\n","#              https://medium.com/@ODSC/how-to-leverage-pre-trained-layers-in-image-classification-31fb9b8cdd0\n","#              https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a\n","#Also based this a lot on the work of the other teammates too :)\n","import numpy as np\n","import pandas as pd\n","from pandas import DataFrame, Series\n","import datetime\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import json \n","from pandas.io.json import json_normalize\n","import seaborn as sns\n","\n","from PIL import Image\n","from io import BytesIO\n","import requests\n","\n","import tensorflow\n","import keras\n","from keras.applications import vgg16, inception_v3, resnet50, mobilenet\n","from keras import models\n","# imports for loading and viewing image \n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.applications.imagenet_utils import decode_predictions"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n","Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"0KaSTy7jjdqQ","colab_type":"code","colab":{}},"source":["import glob\n","from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jG-BMnlwkU0m","colab_type":"code","outputId":"679cd0f5-32b5-4dfc-ede0-6907701e8e41","executionInfo":{"status":"error","timestamp":1589214962479,"user_tz":-420,"elapsed":32757,"user":{"displayName":"Duc Trinh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3DueJ-17c3iJPH_c7OMUo_rfEVfRvjkQWSrqG=s64","userId":"03125855697250476054"}},"colab":{"base_uri":"https://localhost:8080/","height":407}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-4996ee3d8d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0moauth_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mproblem_and_stopped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mdrive_exited\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     ])\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect\u001b[0;34m(self, pattern, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mcompiled_pattern_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_pattern_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         return self.expect_list(compiled_pattern_list,\n\u001b[0;32m--> 344\u001b[0;31m                 timeout, searchwindowsize, async_)\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     def expect_list(self, pattern_list, timeout=-1, searchwindowsize=-1,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexpect_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     def expect_exact(self, pattern_list, timeout=-1, searchwindowsize=-1,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mincoming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincoming\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Keep reading until exception or return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"T-GFh5c6lDzl","colab_type":"code","colab":{}},"source":["import os\n","cwd = os.getcwd()\n","print(cwd)\n","directory = '/content/gdrive/My Drive/data'\n","[x[0] for x in os.walk(directory)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R0O2kR8djdqT","colab_type":"code","colab":{}},"source":["IMG_DIM = (224, 224)\n","\n","train_files = glob.glob('/content/gdrive/My Drive/data/training_data/*')\n","train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]\n","train_imgs = np.array(train_imgs)\n","\n","validation_files = glob.glob('/content/gdrive/My Drive/data/validation_data/*')\n","validation_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in validation_files]\n","validation_imgs = np.array(validation_imgs)\n","\n","print('Train dataset shape:', train_imgs.shape, \n","      '\\tValidation dataset shape:', validation_imgs.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PBvaA8EPtiZ_","colab_type":"code","colab":{}},"source":["train_labels = [fn.split('/')[-1].split('.')[0].strip() for fn in train_files]\n","validation_labels = [fn.split('/')[-1].split('.')[0].strip() for fn in validation_files]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gUaXJHZgjdqW","colab_type":"code","colab":{}},"source":["train_imgs_scaled = train_imgs.astype('float32')\n","validation_imgs_scaled  = validation_imgs.astype('float32')\n","train_imgs_scaled /= 255\n","validation_imgs_scaled /= 255\n","\n","print(train_imgs[0].shape)\n","array_to_img(train_imgs[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QYpWW3A_jdqZ","colab_type":"code","colab":{}},"source":["batch_size = 30\n","num_classes = 2\n","epochs = 100\n","input_shape = (224, 224, 3)\n","\n","# encode text category labels\n","from sklearn.preprocessing import LabelEncoder\n","\n","le = LabelEncoder()\n","le.fit(train_labels)\n","train_labels_enc = le.transform(train_labels)\n","validation_labels_enc = le.transform(validation_labels)\n","\n","print(train_labels[1495:1505], train_labels_enc[1495:1505]) #0 is dank, 1 is not dank"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lTFBImscjdqm","colab_type":"code","colab":{}},"source":["from keras.models import Model\n","vgg = vgg16.VGG16(include_top=False, weights='imagenet', \n","                                     input_shape=input_shape)\n","\n","output = vgg.layers[-1].output\n","output = keras.layers.Flatten()(output)\n","vgg_model = Model(vgg.input, output)\n","\n","vgg_model.trainable = False\n","for layer in vgg_model.layers:\n","    layer.trainable = False\n","pd.set_option('max_colwidth', -1)\n","layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\n","pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable']).tail(20)    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vIS_w7l6jdqp","colab_type":"code","colab":{}},"source":["bottleneck_feature_example = vgg.predict(train_imgs_scaled[0:1])\n","print(bottleneck_feature_example.shape)\n","plt.imshow(bottleneck_feature_example[0][:,:,0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VXEtKKB9jdqr","colab_type":"code","colab":{}},"source":["#unfreeze some layers\n","vgg_model.trainable = True\n","\n","retrain_layers = ['block3_conv1','block5_conv1', 'block4_conv1']\n","set_trainable = False\n","for layer in vgg_model.layers:\n","    if layer.name in retrain_layers:\n","        set_trainable = True\n","    if set_trainable:\n","        layer.trainable = True\n","    else:\n","        layer.trainable = False\n","        \n","layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\n","pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable']).tail(20)   "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"agVLuv5Jjdqu","colab_type":"code","colab":{}},"source":["# Image Augmentation generator to create variety of images\n","train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,\n","                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n","                                   horizontal_flip=True, fill_mode='nearest')\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","train_generator = train_datagen.flow(train_imgs, train_labels_enc, batch_size=30)\n","val_generator = val_datagen.flow(validation_imgs, validation_labels_enc, batch_size=20)       "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IL0rms5Pjdqy","colab_type":"code","colab":{}},"source":["from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n","from keras.models import Sequential\n","from keras import optimizers\n","from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adagrad\n","\n","model = Sequential()\n","model.add(vgg_model)\n","model.add(Dense(512, activation='relu', input_dim=input_shape))\n","model.add(Dropout(0.2))\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer=optimizers.RMSprop(lr=1e-4),\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-_ECseynjdq3","colab_type":"code","colab":{}},"source":["history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=200,\n","                              validation_data=val_generator, validation_steps=50, \n","                              verbose=1)     "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1RLrP1Uqjdq8","colab_type":"code","colab":{}},"source":["f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n","t = f.suptitle('Transfer Learning CNN Performance', fontsize=12)\n","f.subplots_adjust(top=0.85, wspace=0.3)\n","\n","epoch_list = list(range(1,201))\n","ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n","ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n","ax1.set_xticks(np.arange(0, 201, 20))\n","ax1.set_ylabel('Accuracy Value')\n","ax1.set_xlabel('Epoch')\n","ax1.set_title('Accuracy')\n","l1 = ax1.legend(loc=\"best\")\n","\n","ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n","ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n","ax2.set_xticks(np.arange(0, 201, 20))\n","ax2.set_ylabel('Loss Value')\n","ax2.set_xlabel('Epoch')\n","ax2.set_title('Loss')\n","l2 = ax2.legend(loc=\"best\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2GFSHIcSZKeY","colab_type":"code","colab":{}},"source":["model.save('/content/gdrive/My Drive/models/tlearn_finetune_img_aug_vgg16_0.2_dropout_cnn.h5')"],"execution_count":0,"outputs":[]}]}
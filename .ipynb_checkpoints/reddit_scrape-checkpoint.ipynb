{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Praw\n",
      "  Downloading https://files.pythonhosted.org/packages/25/c0/b9714b4fb164368843b41482a3cac11938021871adf99bf5aaa3980b0182/praw-6.5.1-py3-none-any.whl (134kB)\n",
      "Collecting websocket-client>=0.54.0 (from Praw)\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
      "Collecting prawcore<2.0,>=1.0.1 (from Praw)\n",
      "  Downloading https://files.pythonhosted.org/packages/76/b5/ce6282dea45cba6f08a30e25d18e0f3d33277e2c9fcbda75644b8dc0089b/prawcore-1.0.1-py2.py3-none-any.whl\n",
      "Collecting update-checker>=0.16 (from Praw)\n",
      "  Downloading https://files.pythonhosted.org/packages/17/c9/ab11855af164d03be0ff4fddd4c46a5bd44799a9ecc1770e01a669c21168/update_checker-0.16-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in c:\\users\\t$\\appdata\\roaming\\python\\python37\\site-packages (from websocket-client>=0.54.0->Praw) (1.12.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\anaconda\\lib\\site-packages (from prawcore<2.0,>=1.0.1->Praw) (2.21.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->Praw) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\anaconda\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->Praw) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->Praw) (2019.3.9)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->Praw) (2.8)\n",
      "Installing collected packages: websocket-client, prawcore, update-checker, Praw\n",
      "Successfully installed Praw-6.5.1 prawcore-1.0.1 update-checker-0.16 websocket-client-0.57.0\n",
      "Requirement already up-to-date: praw in c:\\anaconda\\lib\\site-packages (6.5.1)\n",
      "Requirement already satisfied, skipping upgrade: prawcore<2.0,>=1.0.1 in c:\\anaconda\\lib\\site-packages (from praw) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client>=0.54.0 in c:\\anaconda\\lib\\site-packages (from praw) (0.57.0)\n",
      "Requirement already satisfied, skipping upgrade: update-checker>=0.16 in c:\\anaconda\\lib\\site-packages (from praw) (0.16)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0,>=2.6.0 in c:\\anaconda\\lib\\site-packages (from prawcore<2.0,>=1.0.1->praw) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\t$\\appdata\\roaming\\python\\python37\\site-packages (from websocket-client>=0.54.0->praw) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->praw) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->praw) (1.24.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->praw) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\anaconda\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->praw) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "# !pip install Praw\n",
    "# !pip install --upgrade praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install Praw\n",
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import json\n",
    "\n",
    "f = open(\"../secret_python.txt\", \"r\")\n",
    "client_id = f.readline().rstrip()\n",
    "secret_key = f.readline().rstrip()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit = praw.Reddit(client_id=client_id, \\\n",
    "                     client_secret=secret_key, \\\n",
    "                     user_agent='Scrape')\n",
    "\n",
    "reddit.read_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dank_meme = reddit.subreddit('dank_meme')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "memesDict = {}\n",
    "memesDict[\"_default\"] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://stackoverflow.com/questions/40960449/getting-all-submissions-for-the-past-two-months-from-a-particular-subreddit-usi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = dt.datetime.now()\n",
    "a_month_ago = current_time-dt.timedelta(days = 30)\n",
    "two_month_ago = current_time-dt.timedelta(days = 60)\n",
    "epoch_start = dt.datetime.timestamp(two_month_ago)\n",
    "epoch_end = dt.datetime.timestamp(a_month_ago)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'timestamp:{}..{}'.format(epoch_start, epoch_end)\n",
    "search_results = dank_meme.search(query,limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 1\n",
    "for submission in dank_meme.hot(limit = 100):\n",
    "#for submission in search_results:\n",
    "    #print(dt.datetime.fromtimestamp(submission.created_utc)) \n",
    "    memesDict[\"_default\"][iterator] = {\"title\":submission.title, \"thumbnail\":{\"thumbnail\":submission.thumbnail, \"height\":submission.thumbnail_height, \"width\":submission.thumbnail_width}, \"created_utc\":submission.created_utc, \"author\":submission.author.name, \"id\":submission.id, \"ups\":submission.ups, \"downs\":submission.downs, \"media\": submission.url}\n",
    "    iterator +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Where is covid 1 - 18', 'thumbnail': {'thumbnail': 'https://b.thumbs.redditmedia.com/Xe4d0LtDHY-cC7XQr-jw-bpmb5VeyRgUAKFCSEeqWVI.jpg', 'height': 140, 'width': 140}, 'created_utc': 1586552261.0, 'author': 'dat1ssjguy', 'id': 'fyoml4', 'ups': 12108, 'downs': 0, 'media': 'https://i.redd.it/yn8htm3x02s41.jpg'}\n"
     ]
    }
   ],
   "source": [
    "print(memesDict[\"_default\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('memesDatabase.json', 'w') as json_file:\n",
    "    json.dump(memesDict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to find out what fields does an object have\n",
    "#import pprint\n",
    "#pprint.pprint(vars(submission))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pushshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With help from the following link: https://medium.com/@RareLoot/using-pushshifts-api-to-extract-reddit-submissions-fb517b286563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://api.pushshift.io/\"\n",
    "fields=\"author,subreddit,preview,all_awardings,score\"\n",
    "def queryBySub(sub, before=\"30d\", after=\"60d\", sort_type=\"score\", size=\"25\", fields=fields):\n",
    "    url = base_url + \"reddit/search/submission/?subreddit=\"+sub+\"&sort_type=\"+sort_type+\"&size=\"+size+\"&after=\"+after+\"&before=\"+before+\"&fields=\"+fields\n",
    "    response = requests.get(url)\n",
    "    return json.loads(response.text)\n",
    "data = queryBySub(\"dank_meme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
